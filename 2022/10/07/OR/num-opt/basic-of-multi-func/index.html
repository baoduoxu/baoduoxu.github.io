<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.2.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/infinity-solid.svg">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/infinity-solid.svg">
  <link rel="mask-icon" href="/images/infinity-solid.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Palatino:300,300italic,400,400italic,700,700italic%7CCascadia+Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="[object Object]">

<link href="https://fonts.googleapis.com/css?family=Noto+Serif+SC|Roboto&display=swap" rel="stylesheet">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.18.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"mac"},"fold":{"enable":true,"height":200},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="实值向量函数对向量和矩阵求导。">
<meta property="og:type" content="article">
<meta property="og:title" content="最优化（二）：多元函数与无约束优化基础">
<meta property="og:url" content="http://example.com/2022/10/07/OR/num-opt/basic-of-multi-func/index.html">
<meta property="og:site_name" content="XBD">
<meta property="og:description" content="实值向量函数对向量和矩阵求导。">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-10-07T07:21:28.000Z">
<meta property="article:modified_time" content="2023-09-12T11:20:06.541Z">
<meta property="article:author" content="Baoduo Xu">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/2022/10/07/OR/num-opt/basic-of-multi-func/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2022/10/07/OR/num-opt/basic-of-multi-func/","path":"2022/10/07/OR/num-opt/basic-of-multi-func/","title":"最优化（二）：多元函数与无约束优化基础"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>最优化（二）：多元函数与无约束优化基础 | XBD</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">XBD</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Everything will end up being TRIVIAL.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E5%85%83%E5%87%BD%E6%95%B0%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5"><span class="nav-number">1.</span> <span class="nav-text">多元函数相关概念</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B0%B4%E5%B9%B3%E9%9B%86"><span class="nav-number">1.1.</span> <span class="nav-text">水平集</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E9%9B%85%E5%8F%AF%E6%AF%94%E7%9F%A9%E9%98%B5%E4%B8%8E%E9%BB%91%E5%A1%9E%E7%9F%A9%E9%98%B5"><span class="nav-number">1.2.</span> <span class="nav-text">梯度、雅可比矩阵与黑塞矩阵</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%9A%E7%BB%B4%E5%AE%9E%E5%80%BC%E5%87%BD%E6%95%B0-%E5%AF%B9%E5%90%91%E9%87%8F%E6%B1%82%E5%AF%BC"><span class="nav-number">1.2.1.</span> <span class="nav-text">多维实值函数: 对向量求导</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BA%8C%E6%AC%A1%E5%9E%8B%E5%87%BD%E6%95%B0%E6%80%A7%E8%B4%A8"><span class="nav-number">1.2.1.1.</span> <span class="nav-text">二次型函数性质</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E7%9F%A9%E9%98%B5%E4%B8%8E%E9%9B%85%E5%8F%AF%E6%AF%94%E7%9F%A9%E9%98%B5"><span class="nav-number">1.2.2.</span> <span class="nav-text">梯度矩阵与雅可比矩阵</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%BB%91%E5%A1%9E%E7%9F%A9%E9%98%B5"><span class="nav-number">1.2.3.</span> <span class="nav-text">黑塞矩阵</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#taylor%E5%B1%95%E5%BC%80"><span class="nav-number">1.3.</span> <span class="nav-text">Taylor展开</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9B%86%E5%90%88%E7%BA%A6%E6%9D%9F%E4%BC%98%E5%8C%96"><span class="nav-number">2.</span> <span class="nav-text">集合约束优化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%AF%E8%A1%8C%E6%96%B9%E5%90%91"><span class="nav-number">2.1.</span> <span class="nav-text">可行方向</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%B9%E5%90%91%E5%AF%BC%E6%95%B0"><span class="nav-number">2.1.1.</span> <span class="nav-text">方向导数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E9%98%B6%E5%BF%85%E8%A6%81%E6%9D%A1%E4%BB%B6"><span class="nav-number">2.2.</span> <span class="nav-text">一阶必要条件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E9%98%B6%E5%BF%85%E8%A6%81%E6%9D%A1%E4%BB%B6"><span class="nav-number">2.3.</span> <span class="nav-text">二阶必要条件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%85%E5%88%86%E6%9D%A1%E4%BB%B6"><span class="nav-number">2.4.</span> <span class="nav-text">充分条件</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A1%A5%E5%85%85-%E5%AF%B9%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC"><span class="nav-number">3.</span> <span class="nav-text">补充: 对矩阵求导</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Baoduo Xu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">47</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="/baoduo_xu@foxmail.com" title="E-Mail → baoduo_xu@foxmail.com" rel="noopener me"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/ta-mei-yu-zhi-jian-de-wen-rou" title="Zhihu → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;ta-mei-yu-zhi-jian-de-wen-rou" rel="noopener me" target="_blank"><i class="fab fa-zhihu fa-fw"></i>Zhihu</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/10/07/OR/num-opt/basic-of-multi-func/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Baoduo Xu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="XBD">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="最优化（二）：多元函数与无约束优化基础 | XBD">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          最优化（二）：多元函数与无约束优化基础
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-10-07 15:21:28" itemprop="dateCreated datePublished" datetime="2022-10-07T15:21:28+08:00">2022-10-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-09-12 19:20:06" itemprop="dateModified" datetime="2023-09-12T19:20:06+08:00">2023-09-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Optimization/" itemprop="url" rel="index"><span itemprop="name">Optimization</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>13k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>12 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h2 id="多元函数相关概念">多元函数相关概念</h2>
<h3 id="水平集">水平集</h3>
<p>曲面 <span class="math inline">\(F(x,y,z)=0\)</span> 的水平集为 <span
class="math inline">\(S=\{(x,y)|F(x,y,c)=0\}.\)</span></p>
<p>不同的水平集不相交;</p>
<p>水平集稠密的地方目标函数函数变化较快, 稀疏的地方变化较慢.</p>
<p>在极值点附近, 水平集会呈现为同心椭圆集.</p>
<h3 id="梯度雅可比矩阵与黑塞矩阵">梯度、雅可比矩阵与黑塞矩阵</h3>
<h4 id="多维实值函数-对向量求导">多维实值函数: 对向量求导</h4>
<p>若 <span class="math inline">\(f:\mathbb{R}^n\to\mathbb{R}\)</span>
且在定义域内一阶可微, 我们可以求出来 <span class="math display">\[
\frac{\partial f}{\partial \mathbf{x}}=\frac{\partial
f}{\partial(x_1,\cdots,x_n)}=\left[\frac{\partial f}{\partial
x_1},\cdots,\frac{\partial f}{\partial x_n}\right],
\]</span> 上面的 <span class="math inline">\(\frac{\partial
f}{\partial(x_1,\cdots,x_n)}\)</span> 可以看作一个形式上的记号, 表示
<span class="math inline">\(f\)</span> 对这些变量求偏导,
最后得到的是一个<strong>行向量</strong>. 同时定义 <span
class="math inline">\(f(\mathbf{x})\)</span> 的梯度 <span
class="math inline">\(\nabla f(\mathbf{x})=\left(\frac{\partial
f}{\partial \mathbf{x}}\right)^{\top} .\)</span>
多元实值函数的梯度是一个<strong>列向量</strong>, 是一个 <span
class="math inline">\(\mathbb{R}^n\to\mathbb{R}^n\)</span> 的函数.</p>
<blockquote>
<p>查到的一些资料给出的规则是对列/行向量求导得到的是列/行向量,
与上面的描述不知为何有些矛盾.</p>
</blockquote>
<p>就像一元函数在给出导函数的定义后推出一些常用的导数公式那样,
对于高维实值函数也有类似的公式(下面默认 <span
class="math inline">\(\mathbf{x}\)</span> 为变量而 <span
class="math inline">\(\mathbf{c}\)</span> 为常量):</p>
<ul>
<li><p><span class="math inline">\(\nabla
\mathbf{c}=\mathbf{0}.\)</span></p></li>
<li><p><span class="math inline">\(\nabla \mathbf{c}^{\top} \mathbf{x}=
\mathbf{c}.\)</span></p></li>
<li><p><span class="math inline">\(\nabla \mathbf{x}^{\top}
\mathbf{x}=2\mathbf{x}.\)</span></p>
<p><strong><em>PROOF</em></strong> <span class="math display">\[
\nabla \mathbf{x}^{\top}
\mathbf{x}=\left(\frac{\partial\sum_{i}x_i^2}{\partial
(x_1,\cdots,x_n)}\right)^{\top} =[2x_1,\cdots,2x_n]^{\top} =2\mathbf{x}.
\]</span></p></li>
<li><p><span class="math inline">\(\nabla \mathbf{x}^{\top}
\mathbf{Ax}=(\mathbf{A}+\mathbf{A}^{\top}) \mathbf{x}.\)</span></p>
<p><strong><em>PROOF</em></strong></p>
<p><span class="math display">\[
\begin{aligned}
\nabla \mathbf{x}^{\top} \mathbf{Ax}
&amp;=\left(\frac{\partial \sum_{i}x_{i}\sum_{j}a_{ij}x_{j}}{\partial
(x_1,\cdots,x_n)}\right)^{\top} \newline{}
&amp;=\left[\sum_{j}x_1(a_{j1}+a_{1j}),\cdots,\sum_{j}x_n(a_{jn}+a_{nj})
\right]^{\top} \newline{}
&amp;=\left[\sum_{j}x_1a_{j1},\cdots,\sum_{j}x_na_{jn}+\right]^{\top}+\left[\sum_{j}x_1a_{1j},\cdots,2\sum_{j}x_na_{nj}
\right]^{\top}\newline{}
&amp;=(\mathbf{x}^{\top} \mathbf{A}+\mathbf{x}^{\top}
\mathbf{A}^{\top})^{\top}\newline{}
&amp;=(\mathbf{A}+\mathbf{A}^{\top})\mathbf{x}
\end{aligned}
\]</span></p>
<p><span class="math inline">\(\mathbf{x}^{\top} \mathbf{Ax}\)</span>
是二次型函数, 对于不对称的 <span
class="math inline">\(\mathbf{A}\)</span> 我们总可以用下述手段让其对称:
令 <span
class="math inline">\(\mathbf{B}=\frac{1}{2}\left(\mathbf{A}+\mathbf{A}^{\top}
\right),\)</span> <span class="math inline">\(\mathbf{B}^{\top}
=\mathbf{B},\)</span> 且</p></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\mathbf{x}^{\top} \mathbf{Ax}
&amp;=\sum_{i}\sum_{j}a_{ij}x_ix_j\newline{}
&amp;=\frac{1}{2}\sum_i\sum_ja_{ij}x_ix_j+\frac{1}{2}\sum_{i}\sum_ja_{ij}x_ix_j\newline{}
&amp;=\frac{1}{2}\sum_i\sum_ja_{ij}x_ix_j+\frac{1}{2}\sum_{i}\sum_{j}a_{ji}x_ix_j\newline{}
&amp;=\sum_{i}\sum_{j}\frac{a_{ij}+a_{ji}}{2}x_ix_j\newline{}
&amp;=\mathbf{x}^{\top} \mathbf{Bx}.
\end{aligned}
\]</span></p>
<p>于是在处理的时候 <span class="math inline">\(\mathbf{A}\)</span>
往往是实对称矩阵, 也就有 <span class="math inline">\(\nabla
\mathbf{x}^{\top} \mathbf{Ax}=2\mathbf{Ax}\)</span> 成立.</p>
<p>有时候也会称函数 <span
class="math inline">\(f(\mathbf{x})=\mathbf{x}^{\top}
\mathbf{Ax}+\mathbf{b}^{\top} \mathbf{x}+c\)</span>
为一般的二次型函数.</p>
<h5 id="二次型函数性质">二次型函数性质</h5>
<p>给定对称矩阵 <span class="math inline">\(\mathbf{Q}\in
\mathbb{R}^{n\times n},\)</span> 若 <span class="math inline">\(\forall
\mathbf{x}\in\mathbb{R}^n\backslash\{\mathbf{0}\}\)</span> 都有 <span
class="math inline">\(\mathbf{x}^{\top} \mathbf{Qx}&gt;0\)</span> 成立,
则称 <span class="math inline">\(\mathbf{Q}\)</span> 是一个正定矩阵;
若仅有 <span class="math inline">\(\mathbf{x}^{\top} \mathbf{Qx}\ge
0\)</span> 成立则称 <span class="math inline">\(\mathbf{Q}\)</span>
为半正定矩阵. 类似也可定义负定矩阵与半负定矩阵.</p>
<p><strong>定理1 (Sylvester 定理)</strong> 对称矩阵 <span
class="math inline">\(\mathbf{Q}\)</span> 为正定矩阵当且仅当 <span
class="math inline">\(\mathbf{Q}\)</span> 的顺序主子式是正定的.</p>
<p><strong>定理2</strong> 对称矩阵 <span
class="math inline">\(\mathbf{Q}\)</span> 是正定/半正定当且仅当 <span
class="math inline">\(\mathbf{Q}\)</span> 的所有特征值都是正/非负的.</p>
<h4 id="梯度矩阵与雅可比矩阵">梯度矩阵与雅可比矩阵</h4>
<p>我们现在给出函数 <span class="math inline">\(\mathbf{f}:\mathbb{R}^n
\to\mathbb{R}^m\)</span> 对向量 <span
class="math inline">\(\mathbf{x}\)</span> 求导的公式. <span
class="math inline">\(\mathbf{f}\)</span> 是一个列向量: <span
class="math inline">\(\mathbf{f}=[f_1,\cdots,f_m]^{\top} ,\)</span> 对
<span class="math inline">\(\mathbf{x}\)</span> 求导相当于每一个分量
<span class="math inline">\(f_i\)</span> 对 <span
class="math inline">\(\mathbf{x}\)</span> 求导, 而每一个 <span
class="math inline">\(\frac{\partial f_i}{\partial \mathbf{x}}\)</span>
又是一个行向量, 于是 <span class="math display">\[
\frac{\partial \mathbf{f}}{\partial\mathbf{x}}=
\begin{bmatrix}
\frac{\partial f_1}{\partial \mathbf{x}}\newline{}
\vdots\newline{}
\frac{\partial f_m}{\partial \mathbf{x}}
\end{bmatrix}
=
\begin{bmatrix}
\frac{\partial f_1}{\partial x_1}&amp;\cdots&amp;\frac{\partial
f_1}{\partial x_n}\newline{}
\vdots&amp;&amp;\vdots\newline{}
\frac{\partial f_m}{\partial x_1}&amp;\cdots&amp;\frac{\partial
f_m}{\partial x_n}
\end{bmatrix}
\]</span> 这是所谓的<strong>导数矩阵</strong>,
又称为雅可比矩阵(Jacobian), 记作 <span
class="math inline">\(\mathscr{D}\mathbf{f}(\mathbf{x})\)</span> 或者
<span class="math inline">\(J\mathbf{f}(\mathbf{x}),\)</span> 它是 <span
class="math inline">\(m\times n\)</span> 矩阵.
同样定义<strong>梯度矩阵</strong> <span class="math inline">\(\nabla
\mathbf{f}(\mathbf{x})=(\mathscr{D}\mathbf{f}(\mathbf{x}))^{\top}
,\)</span> 梯度矩阵是 <span class="math inline">\(n\times m\)</span>
矩阵.</p>
<p>因此对于实值函数 <span
class="math inline">\(f:\mathbb{R}^n\to\mathbb{R}\)</span> ,
它的雅可比矩阵 <span
class="math inline">\(\mathscr{D}f(\mathbf{x})\)</span>
是一个行向量.</p>
<h4 id="黑塞矩阵">黑塞矩阵</h4>
<p>对于实值函数 <span
class="math inline">\(f:\mathbb{R}^n\to\mathbb{R},\)</span> 若梯度 <span
class="math inline">\(\nabla f\)</span> 可微, 则称 <span
class="math inline">\(f\)</span> 二阶可微, <span
class="math inline">\(\nabla f\)</span> 的导数记为 <span
class="math display">\[
\mathscr{D}^2 f=\left[\begin{array}{cccc}
\frac{\partial ^2 f}{\partial  x_1^2} &amp; \frac{\partial ^2
f}{\partial  x_2 \partial  x_1} &amp; \cdots &amp; \frac{\partial ^2
f}{\partial  x_n \partial  x_1} \newline{}
\frac{\partial ^2 f}{\partial  x_1 \partial  x_2} &amp; \frac{\partial
^2 f}{\partial  x_2^2} &amp; \cdots &amp; \frac{\partial ^2
f}{\partial  x_n \partial  x_2} \newline{}
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \newline{}
\frac{\partial ^2 f}{\partial  x_1 \partial  x_n} &amp; \frac{\partial
^2 f}{\partial  x_2 \partial  x_n} &amp; \cdots &amp; \frac{\partial ^2
f}{\partial  x_n^2}
\end{array}\right].
\]</span> 矩阵 <span class="math inline">\(\mathscr{D}^2
f(\mathbf{x})\)</span> 被称为 <span class="math inline">\(f\)</span>
(在点 <span class="math inline">\(\mathbf{x}\)</span>
处)的黑塞矩阵(Hessian). 本文中也会用 <span
class="math inline">\(\nabla^2 f(\mathbf{x})\)</span> 表示黑塞矩阵.</p>
<p>若 <span class="math inline">\(f\)</span> 是二阶连续可微的, 则 <span
class="math inline">\(f\)</span> 的黑塞矩阵是对称的.</p>
<p>一个实例: <span class="math inline">\(f(\mathbf{x})\)</span>
在定义域内二阶可微, <span
class="math inline">\(\phi(\alpha)=f(\mathbf{x}+\alpha\mathbf{p}),\)</span>
求 <span
class="math inline">\(\phi&#39;(\alpha),\phi&#39;&#39;(\alpha).\)</span></p>
<p><strong><em>SOL</em></strong> 这个函数是以后经常碰到的函数,
直接用链式法则即可: <span class="math display">\[
\begin{aligned}\phi&#39;(\alpha)=\nabla f(\mathbf{x}+\alpha
\mathbf{p})^{\top}\mathbf{p}\newline{}\phi&#39;&#39;(\alpha)=p^{\top}\nabla^2
f(\mathbf{x}+\alpha \mathbf{p})\mathbf{p}\end{aligned}
\]</span></p>
<h3 id="taylor展开">Taylor展开</h3>
<blockquote>
<p><strong>Theorem</strong><a href="#fn1" class="footnote-ref"
id="fnref1" role="doc-noteref"><sup>1</sup></a> (Taylor) Suppose <span
class="math inline">\(f\)</span> from <span
class="math inline">\(\mathbb{R}^n\)</span> to <span
class="math inline">\(\mathbb{R}\)</span> is a <span
class="math inline">\(C^{m+1}\)</span> function on an open ball centered
at <span class="math inline">\(\mathbf{A}\)</span>. Then for <span
class="math inline">\(\mathbf{A}+\mathbf{H}\)</span> in the ball, <span
class="math display">\[
\begin{gathered}f(\mathbf{A}+\mathbf{H})=f(\mathbf{A})+\sum_{i_1=1}^n
h_{i_1} f_{x_{i_1}}(\mathbf{A})+\frac{1}{2} \sum_{i_1, i_2=1}^n h_{i_1}
h_{i_2} f_{x_{i_1} x_{i_2}}(\mathbf{A}) \newline{}+\cdots+\frac{1}{m !}
\sum_{i_1, \ldots, i_m=1}^n\left(h_{i_1} h_{i_2} \cdots h_{i_m}\right)
f_{x_{i_1} x_{i_2} \cdots x_{i_m}}(\mathbf{A})+R_m(\mathbf{A},
\mathbf{H}),\end{gathered}
\]</span> where <span class="math inline">\(\left|R_m(\mathbf{A},
\mathbf{H})\right| \leq k\|\mathbf{H}\|^{m+1}\)</span> for some constant
<span class="math inline">\(k\)</span>. The remainder goes to zero
faster than <span class="math inline">\(\|\mathbf{H}\|^m\)</span> in the
sense that <span class="math display">\[
0 \leq \frac{\left|R_m(\mathbf{A}, \mathbf{H})\right|}{\|\mathbf{H}\|^m}
\leq k\|\mathbf{H}\| .
\]</span></p>
</blockquote>
<p>当然常用的Taylor展开只需要展开到一阶或二阶即可.</p>
<p>若函数 <span
class="math inline">\(f:\mathbb{R}^n\to\mathbb{R},\)</span> 在开集 <span
class="math inline">\(\Omega\subset \mathbb{R}^n\)</span>
上一阶/二阶连续可微, 且 <span
class="math inline">\(\mathbf{x_0}\in\Omega,\)</span> 则</p>
<p>一阶: <span class="math display">\[
f(\mathbf{x})=f(\mathbf{x}_0)+\nabla f(\mathbf{x})^{\top}
(\mathbf{x}-\mathbf{x}_0)+o(\|\mathbf{x}-\mathbf{x}_0\|).
\]</span> 二阶: <span class="math display">\[
f(\mathbf{x})=f(\mathbf{x}_0)+\nabla f(\mathbf{x})^{\top}
(\mathbf{x}-\mathbf{x}_0)+\frac{1}{2}(\mathbf{x}-\mathbf{x}_0)^{\top}
\nabla^2f(\mathbf{x}_0)(\mathbf{x}-\mathbf{x}_0)+o(\|\mathbf{x}-\mathbf{x}_0\|^2).
\]</span></p>
<blockquote>
<p>这里不是数学笔记就不补充证明过程了.</p>
</blockquote>
<h2 id="集合约束优化">集合约束优化</h2>
<p>集合约束优化是形如 <span class="math display">\[
\begin{aligned}
&amp;\min f(\mathbf{x})\newline{}
\text{s.t. }&amp;\mathbf{x}\in\Omega
\end{aligned}
\]</span> 的优化问题, 其中 <span class="math inline">\(f:\Omega\subset
\mathbb{R}^n\to\mathbb{R}.\)</span> 由于最小值会在极小值点取到,
先给出两类极小点的定义.</p>
<p><strong>定义1</strong> 对于 <span class="math inline">\(f\)</span>
定义域中的一个点 <span class="math inline">\(\mathbf{x}^{\ast},\)</span>
若存在 <span class="math inline">\(\mathbf{x}^{\ast}\)</span>
的一个去心邻域 <span
class="math inline">\(\tilde{U}(\mathbf{x}^{\ast})\)</span> 使得 <span
class="math inline">\(\forall \mathbf{x}\in
\tilde{U}(\mathbf{x}^{\ast}),\)</span> 不等式 <span
class="math inline">\(f(\mathbf{x})\ge f(\mathbf{x}^{\ast})\)</span>
都成立, 则称 <span class="math inline">\(\mathbf{x}^{\ast}\)</span> 是
<span class="math inline">\(f\)</span> 在 <span
class="math inline">\(\Omega\)</span>
中的一个<strong>局部极小点</strong>. 若 <span
class="math inline">\(\forall
\mathbf{x}\in\Omega\backslash\{\mathbf{x}^{\ast}\}\)</span> 不等式 <span
class="math inline">\(f(\mathbf{x})\ge f(\mathbf{x}^{\ast})\)</span>
都成立, 则称 <span class="math inline">\(\mathbf{x}^{\ast}\)</span> 是
<span class="math inline">\(f\)</span> 在 <span
class="math inline">\(\Omega\)</span>
中的一个<strong>全局极小点</strong>. <span
class="math inline">\(\square\)</span></p>
<p>若将 <span class="math inline">\(\ge\)</span> 改成 <span
class="math inline">\(&gt;,\)</span>
则得到的是<strong>严格</strong>局部极小点和<strong>严格</strong>全局极小点的定义.</p>
<p>根据极小点的定义, 对于优化问题 <span class="math inline">\(\min
f(\mathbf{x}),\text{s.t. }\mathbf{x}\in\Omega,\)</span>
可以给出<strong>局部最优解</strong>与<strong>全局最优解</strong>的定义,
即 <span class="math inline">\(\Omega\)</span>
中的局部极小点为该优化问题的局部最优解,
全局极小点为该优化问题的全局最优解.</p>
<h3 id="可行方向">可行方向</h3>
<p><strong>定义2</strong> 对于 <span
class="math inline">\(\mathbf{d}\in\mathbb{R}^n\land \mathbf{d}\ne
\mathbf{0}\)</span> 和<span
class="math inline">\(\mathbf{x}\in\Omega,\)</span> 若存在一个实数 <span
class="math inline">\(\alpha_0&gt;0\)</span> 使得 <span
class="math inline">\(\forall \alpha\in[0,\alpha_0],\)</span> 都有 <span
class="math inline">\(\mathbf{x}+\alpha\mathbf{d}\in\Omega,\)</span>
则称 <span class="math inline">\(\mathbf{d}\)</span> 为 <span
class="math inline">\(\mathbf{x}\)</span> 处的可行方向. <span
class="math inline">\(\square\)</span></p>
<p>显然若 <span class="math inline">\(\mathbf{x}\)</span> 在 <span
class="math inline">\(\Omega\)</span> 的内部, 任意一个方向都是可行方向;
若 <span class="math inline">\(\mathbf{x}\)</span> 处于边缘,
则肯定某个范围内的方向是不可行的. 为什么我们要关注可行方向? <span
class="math inline">\(\mathbf{x}\)</span>
在约束集边缘和在约束集内部时能使用的信息是不一样的</p>
<h4 id="方向导数">方向导数</h4>
<p>在可行方向定义的基础下，我们给出方向导数的定义。</p>
<p>设 <span class="math inline">\(\mathbf{d}\in \mathbb{R}^n,\)</span>
可微函数 <span class="math inline">\(f(\mathbf{x})\)</span> 在 <span
class="math inline">\(\mathbf{x}\)</span> 处沿 <span
class="math inline">\(\mathbf{d}\)</span> 的方向导数为 <span
class="math display">\[
\frac{\partial f}{\partial \mathbf{d}}(\mathbf{x})=\frac{\mathrm{d}
f(\mathbf{x}+\alpha\mathbf{d})}{\mathrm{d}\alpha}=\nabla
f(\mathbf{x})^{\top} \mathbf{d}.
\]</span> <span class="math inline">\(\square\)</span></p>
<p>方向导数描述了函数 <span class="math inline">\(f(\mathbf{x})\)</span>
在 <span class="math inline">\(\mathbf{x}\)</span> 处沿 <span
class="math inline">\(\mathbf{d}\)</span> 方向变化的快慢,
我们自然关注函数在何方向变化得最快, 也即 <span
class="math inline">\(\mathbf{d}\)</span> 满足什么条件 <span
class="math inline">\(\nabla f(\mathbf{x})^{\top} \mathbf{d}\)</span>
最大. 由Cauchy-Schwartz不等式有 <span class="math inline">\(\|\nabla
f(\mathbf{x})^{\top} \mathbf{d}\|\le \|\nabla f(\mathbf{x})^{\top}
\|\|\mathbf{d}\|\)</span> 当且仅当 <span class="math inline">\(\nabla
f(\mathbf{x})^{\top}\)</span> 和 <span
class="math inline">\(\mathbf{d}\)</span> 在一个方向时取等,
也即在某点沿梯度方向函数 <span class="math inline">\(f(x)\)</span>
拥有最大的增长率, 同理 <span class="math inline">\(f(x)\)</span>
在某点的负梯度方向减小得最快.</p>
<p>这部分实际上是对微积分中多元变量微积分的推广,
因为大部分工科的教材在介绍黑塞矩阵时只给出了二元函数的情形.</p>
<p>下面我们给出某一点是多元函数的极小值点的一些必要条件与充分条件.</p>
<blockquote>
<p>虽然我们更关注的是在约束集 <span
class="math inline">\(\Omega\)</span> 内部的极小点,
但是难免会碰到在边界取得极小值的函数, 所以我们需要都考虑进去.</p>
</blockquote>
<h3 id="一阶必要条件">一阶必要条件</h3>
<p><strong>定理3 (一阶必要条件)</strong> 设 <span
class="math inline">\(f:\mathbb{R}^n\to\mathbb{R}\)</span> 在开集 <span
class="math inline">\(\Omega\)</span> 上连续可微, 若 <span
class="math inline">\(\mathbf{x}^{\ast}\)</span> 是函数 <span
class="math inline">\(f\)</span> 在 <span
class="math inline">\(\Omega\)</span> 上的局部极小点, 则对 <span
class="math inline">\(\mathbf{x}^{\ast}\)</span> 的任意可行方向 <span
class="math inline">\(\mathbf{d}\)</span> 都有 <span
class="math inline">\(\mathbf{d}^{\top} \nabla f(\mathbf{x}^{\ast})\ge
0.\)</span> <span class="math inline">\(\square\)</span></p>
<p><strong><em>PROOF</em></strong> 对任意 <span
class="math inline">\(\alpha&gt; 0\land \mathbf{x}^{\ast}+\alpha
\mathbf{d}\in\Omega,\)</span> 有 <span
class="math inline">\(f(\mathbf{x}^{\ast}+\alpha\mathbf{d})\ge
f(\mathbf{x})\)</span> 成立, 由Taylor展开有 <span
class="math display">\[
\nabla f(\mathbf{x}^{\ast})^{\top} \mathbf{d}+\frac{o(\alpha\|\mathbf{d}
\|)}{\alpha}\ge 0.
\]</span> 取 <span class="math inline">\(\alpha\to 0,\)</span> 便有
<span class="math inline">\(\nabla f(\mathbf{x}^{\ast})^{\top}
\mathbf{d}\ge 0\)</span> 也即 <span
class="math inline">\(\mathbf{d}^{\top} \nabla f(\mathbf{x}^{\ast})\ge
0.\)</span> <span class="math inline">\(\blacksquare\)</span></p>
<p>需要注意的是定理3中 <span class="math inline">\(x^{\ast}\)</span>
并不一定是在约束集内部, 所以我们不能断定 <span
class="math inline">\(\nabla f(x^{\ast})=\mathbf{0}.\)</span></p>
<p><strong>推论1</strong> 设 <span
class="math inline">\(f:\mathbb{R}^n\to\mathbb{R}\)</span> 在开集 <span
class="math inline">\(\Omega\)</span> 上连续可微, 若 <span
class="math inline">\(\mathbf{x}^{\ast}\)</span> 是函数 <span
class="math inline">\(f\)</span> 在 <span
class="math inline">\(\Omega\)</span> 上的局部极小值点<em>且为内点</em>,
则有 <span class="math inline">\(\nabla f(\mathbf{x}^{\ast})=
\mathbf{0}\)</span> 成立.</p>
<p><strong><em>PROOF</em></strong> 由于 <span
class="math inline">\(\mathbf{x}^{\ast}\)</span> 为内点,
可行方向可以任取, 于是取 <span class="math inline">\(\mathbf{d}\)</span>
和 <span class="math inline">\(\mathbf{-d},\)</span> 就有 <span
class="math inline">\(\mathbf{d}^{\top} \nabla f(\mathbf{x}^{\ast})\ge
0,-\mathbf{d}^{\top} \nabla f(\mathbf{x}^{\ast})\ge 0,\)</span>
这就表明了 <span class="math inline">\(\mathbf{d}^{\top} \nabla
f(\mathbf{x}^{\ast})= 0,\)</span> 而 <span
class="math inline">\(\mathbf{d}\)</span> 是任意的, 那么有 <span
class="math inline">\(\nabla f(\mathbf{x}^{\ast})=\mathbf{0}\)</span>
成立. <span class="math inline">\(\blacksquare\)</span></p>
<p>值得注意的是 <span class="math inline">\(\nabla
f(\mathbf{x}^{\ast})=0\)</span> 的点 <span
class="math inline">\(\mathbf{x}^{\ast}\)</span> 被称作为驻点,
并不一定是极值点, 比如马鞍面(双曲抛物面)的鞍点.</p>
<h3 id="二阶必要条件">二阶必要条件</h3>
<blockquote>
<p>这里和前面一样要注意局部极小点可能在边界处.</p>
</blockquote>
<p><strong>定理4 (二阶必要条件)</strong> 设 <span
class="math inline">\(f:\mathbb{R}^n\to\mathbb{R}\)</span> 在约束集
<span class="math inline">\(\Omega\subset \mathbb{R}^n\)</span>
上二阶连续可微, 若 <span
class="math inline">\(\mathbf{x}^{\ast}\)</span> 是函数 <span
class="math inline">\(f\)</span> 在 <span
class="math inline">\(\Omega\)</span> 上的局部极小值点, 且对某个可行方向
<span class="math inline">\(\mathbf{d}\)</span> 有 <span
class="math inline">\(\mathbf{d}^{\top} \nabla
f(\mathbf{x^{\ast}})=0,\)</span> 那么就有 <span
class="math inline">\(\mathbf{d}^{\top} \nabla^2
f(\mathbf{x}^{\ast})\mathbf{d}\ge 0\)</span> 成立. <span
class="math inline">\(\square\)</span></p>
<p><strong><em>PROOF</em></strong> 由 <span
class="math inline">\(\mathbf{d}^{\top} \nabla
f(\mathbf{x^{\ast}})=0\)</span> 可得 <span class="math inline">\(\nabla
f(\mathbf{x^{\ast}})^{\top} \mathbf{d}=0,\)</span> 由于 <span
class="math inline">\(\mathbf{x}^{\ast}\)</span> 是极小点, 于是当正数
<span class="math inline">\(\alpha\)</span> 充分小时一定有 <span
class="math inline">\(f(\mathbf{x}^{\ast}+\alpha\mathbf{d})\ge
f(\mathbf{x}^{\ast}),\)</span> 于是对 <span
class="math inline">\(f(\mathbf{x}^{\ast}+\alpha\mathbf{d})\)</span>
进行Taylor展开, 有 <span class="math display">\[
f(\mathbf{x}^{\ast}+\alpha \mathbf{d})=f(\mathbf{x}^{\ast})+\alpha\nabla
f(\mathbf{x}^{\ast})^{\top}
\mathbf{d}+\frac{1}{2}\alpha^2\mathbf{d}^{\top}
\nabla^2f(\mathbf{x})\mathbf{d}+o(\alpha^2\|\mathbf{d}\|^2)\ge
f(\mathbf{x}^{\ast})
\]</span> 化简有 <span
class="math inline">\(\frac{1}{2}\alpha^2\mathbf{d}^{\top}
\nabla^2f(\mathbf{x})\mathbf{d}+o(\alpha^2\|\mathbf{d}\|^2)\ge
0,\)</span> 于是 <span class="math display">\[
\mathbf{d}^{\top} \nabla^2
f(\mathbf{x}^{\ast})\mathbf{d}+\frac{o(\alpha^2\|\mathbf{d}\|^2)}{2\alpha^2}\ge
0,
\]</span> 取 <span class="math inline">\(\alpha \to 0\)</span> 即得结论.
<span class="math inline">\(\blacksquare\)</span></p>
<p><strong>推论2</strong> 设 <span
class="math inline">\(f:\mathbb{R}^n\to\mathbb{R}\)</span> 在约束集
<span class="math inline">\(\Omega\subset \mathbb{R}^n\)</span>
上二阶连续可微, 若 <span
class="math inline">\(\mathbf{x}^{\ast}\)</span> 是函数 <span
class="math inline">\(f\)</span> 在 <span
class="math inline">\(\Omega\)</span> 上的局部极小值点<em>且为内点</em>,
则对任意可行方向 <span class="math inline">\(\mathbf{d}\)</span> 都有
<span class="math inline">\(\mathbf{d}^{\top} \nabla^2
f(\mathbf{x}^{\ast})\mathbf{d}\ge 0\)</span> 成立, 即黑塞矩阵半正定.
<span class="math inline">\(\square\)</span></p>
<p>证明推论只需要用到一阶必要条件和二阶必要条件即可.</p>
<h3 id="充分条件">充分条件</h3>
<p><strong>引理1 (瑞利不等式)</strong> 设 <span
class="math inline">\(\mathbf{P}\in\mathbb{R}^{n\times n}\)</span>
是实对称矩阵, 则 <span class="math display">\[
\lambda_{\min}(\mathbf{P})\|\mathbf{x}\|^2\le \mathbf{x}^{\top}
\mathbf{Px}\le \lambda_{\max} \|\mathbf{x}\|^2.
\]</span> <span class="math inline">\(\square\)</span></p>
<p><strong>定理5</strong> 设 <span
class="math inline">\(f:\mathbb{R}^n\to\mathbb{R}\)</span> 在 <span
class="math inline">\(\Omega\)</span> 上二阶连续可微, <span
class="math inline">\(x^{\ast}\)</span> 是约束集的一个内点, 若 <span
class="math inline">\(\nabla f(x^{\ast})=0\)</span> 且在 <span
class="math inline">\(x^{\ast}\)</span> 处的黑塞矩阵 <span
class="math inline">\(F(x^{\ast})\)</span> 正定, 则 <span
class="math inline">\(x^{\ast}\)</span> 为 <span
class="math inline">\(f\)</span> 的一个严格局部极小点. <span
class="math inline">\(\square\)</span></p>
<p><strong><em>PROOF</em></strong> 对任意的且范数充分小的可行方向 <span
class="math inline">\(d\)</span> , 对 <span
class="math inline">\(f(x^{\ast}+ d)\)</span> 进行Taylor展开有 <span
class="math display">\[
f(x^{\ast}+d)=f(x^{\ast})+\frac{1}{2}d^{\top} F(x^{\ast})d+o(\|d\|^2),
\]</span> 由于 <span class="math inline">\(F(x^{\ast})\)</span> 正定,
故由瑞利不等式有 <span class="math inline">\(d^{\top} F(x^{\ast})d\ge
\lambda_{\min}(F(x^{\ast}))\|d\|^2&gt;0,\)</span> 且在 <span
class="math inline">\(\|d\|\)</span> 充分小时, 有 <span
class="math inline">\(\|d\|^2&gt;|o(\|d\|^2)|,\)</span> 这表明了 <span
class="math display">\[
\frac{1}{2}d^{\top} F(x^{\ast})d+o(\|d\|^2)&gt;0,
\]</span> 这也就意味着对任意可行方向 <span
class="math inline">\(d\)</span> 都有 <span
class="math inline">\(f(x^{\ast}+d)&gt;f(x^{\ast}),\)</span>
这也就表明了 <span class="math inline">\(x^{\ast}\)</span>
为严格局部极小点. <span class="math inline">\(\blacksquare\)</span></p>
<h2 id="补充-对矩阵求导">补充: 对矩阵求导</h2>
<p>设 <span class="math inline">\(f:\R^{m\times n}\to \R,\)</span> 且
<span class="math inline">\(X=(x_{ij}),\)</span> 定义 <span
class="math display">\[
\nabla_{X}f(X)=\frac{\partial f}{\partial X}=\left(\frac{\partial
f}{\partial x_{ij}}\right)
\]</span> 常见的 <span class="math inline">\(f\)</span>
是矩阵的迹(trace), 即 <span
class="math inline">\(f(X)=\operatorname{tr}(X),X\in\R^{n\times
n},\)</span> 下面是一些公式:</p>
<p>1: <span class="math inline">\(\displaystyle \nabla_X
\operatorname{tr}(AX)=A^T,A\in \R^{n\times m}.\)</span> <span
class="math display">\[
\nabla_X \operatorname{tr}(AX)=\left(\frac{\partial}{\partial
x_{ij}}\sum_{k=1}^{n}\sum_{l=1}^ma_{kl}x_{lk}\right)=(a_{ji})=A^T
\]</span> 2: <span
class="math inline">\(\nabla_X\operatorname{tr}(X^TX)=\nabla_X\operatorname{tr}(XX^T)=2X.\)</span>
<span class="math display">\[
\begin{aligned}
\nabla_X \operatorname{tr}(X^TX)
&amp;=\left(\frac{\partial}{\partial
x_{ij}}\sum_{k=1}^{n}\sum_{l=1}^mx_{lk}^2\right)\newline{}
&amp;=2(x_{ij})\newline{}
&amp;=2X
\end{aligned}
\]</span> 3: <span class="math inline">\(\nabla_X
\operatorname{tr}(X^TQX)=QX+Q^TX,Q\in\R^{m\times m}.\)</span></p>
<p>令 <span
class="math inline">\(X=(\vec{x}_1,\cdots,\vec{x}_n),\vec{x}_i\in
\R^m,\)</span> 则 <span class="math display">\[
\begin{aligned}
\nabla_X \operatorname{tr}(X^TQX)
&amp;=\left(\frac{\partial}{\partial
x_{ij}}\sum_{k=1}^n\vec{x}_k^TQ\vec{x}_k\right)\newline{}
&amp;=\left(\sum_{l=1}^m (q_{il}+q_{li})x_{lj}\right)\newline{}
&amp;=\left(\sum_{l=1}^m q_{il}x_{lj}\right)+\left(\sum_{l=1}^m
q_{li}x_{lj}\right)\newline{}
&amp;=QX+Q^TX
\end{aligned}
\]</span> 如果 <span class="math inline">\(Q\)</span> 为对称阵则 <span
class="math inline">\(\nabla_X\operatorname{tr}(X^TQX)=2QX.\)</span></p>
<p>4: <span class="math inline">\(\nabla_X\operatorname{tr}
(XAX^TB)=BXA+B^TXA^T,A\in\R^{n\times n},B\in\R^{m\times m}.\)</span></p>
<p>5: <span class="math inline">\(\nabla_{X^T} f(X)=(\nabla_X
f(X))^T.\)</span></p>
<p>直接根据定义证即可.</p>
<p>6: <span class="math inline">\(\nabla_X\det
(X)=\det(X)(X^{-1})^T,X\in\R^{n\times n},\det(X)\ne 0.\)</span> 也就是
<span class="math inline">\(\nabla_X\det(X)=(X^*)^T,\)</span> <span
class="math inline">\(X^*\)</span> 为 <span
class="math inline">\(X\)</span> 的伴随矩阵. 根据行列式展开定义证明即可,
即沿 <span class="math inline">\(x_{ij}\)</span> 展开后 <span
class="math inline">\(x_{ij}\)</span> 的系数为 <span
class="math inline">\(x_{ij}\)</span> 的代数余子式 <span
class="math inline">\(X_{ij},\)</span> 于是 <span
class="math inline">\((X_{ij})=(X^*)^T.\)</span></p>
<p>1, 2, 3和对向量求导的结果是一致的.</p>
<p>实值函数对矩阵的高阶导数需要借助张量表示.</p>
<aside id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Peter D. Lax, Maria Shea Terrell: <em>Multivariable
Calculus with Applications</em>.<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</aside>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/10/07/OR/num-opt/one-dim/" rel="prev" title="最优化（一）：一维搜索方法">
                  <i class="fa fa-angle-left"></i> 最优化（一）：一维搜索方法
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/10/07/OR/num-opt/gradient/" rel="next" title="最优化（三）：梯度法">
                  最优化（三）：梯度法 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class=""></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Baoduo Xu</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="Word count total">244k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">3:42</span>
  </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
